Chapter 1 IntroduCtIon to SprIng Boot

Listing 1-1. Example of an XML-Based Configuration

<bean id="userService" class="com.apress.myapp.service.UserService">

<property name="userDao" ref="userDao"/>

</bean>

<bean id="userDao" class="com.apress.myapp.dao.JdbcUserDao">

<property name="dataSource" ref="dataSource"/>

</bean>

<bean id="dataSource" class="org.apache.commons.dbcp.BasicDataSource"

destroy-method="close">

<property name="driverClassName" value="com.mysql.jdbc.Driver"/>

<property name="url" value="jdbc:mysql://localhost:3306/test"/>

<property name="username" value="root"/>

<property name="password" value="secret"/>

</bean>

<!-- DSL based configuration -->

<beans>

<jee:jndi-lookup id="entityManagerFactory" jndi-name="persistence/

defaultPU"/>

</beans>

Listing 1-2. Example of an Annotation-Based Configuration

@Service

public class UserService

{

private final UserDao userDao;

public UserService(UserDao dao){

this.userDao = dao;

}

...

...

}

@Repository

public class JdbcUserDao

{

private final DataSource dataSource;

3

Chapter 1 IntroduCtIon to SprIng Boot

public JdbcUserDao(DataSource dataSource){

this.dataSource = dataSource;

}

...

...

}

Listing 1-3. Example of a JavaConfig-Based Configuration

@Configuration

public class AppConfig

{

@Bean

public UserService userService(UserDao dao){

return new UserService(dao);

}

@Bean

public UserDao userDao(DataSource dataSource){

return new JdbcUserDao(dataSource);

}

@Bean

public DataSource dataSource(){

BasicDataSource dataSource = new BasicDataSource();

dataSource.setDriverClassName("com.mysql.jdbc.Driver");

dataSource.setUrl("jdbc:mysql://localhost:3306/test");

dataSource.setUsername("root");

dataSource.setPassword("secret");

return dataSource;

}

}

**Diseñados para fallar 
Pueden ocurrir por causas desconocidas lejos de tu control.
Falas de base de datos, Acceso a ficheros, sistemas de cache, FAllas en la red

REconexiones a la base de datos, cache local como backup, políticas de reintento de 
fallbacks.

** Evitar la infraestructura Compartida
- evitar el uso de bases de datos compartidas
- Evitar el uso de sistemas de caché compartidos.
-Evitar infraestructura de despliegue compartida.
mismo nodo, máquina virtual, VPS, EC2   


** Dieñado para operar de forma distribuida.

- Evitar aplicaciones co estados, pensar en un modelo stateless en lugar de statefull.
- Pensar en sistemas dsitribuidos de persistencias (Cache/DB), con posibilidad de 
escalar orizontal.
- Escalabilidad Horizontal como principio.


** Confianza cero en terceros 

No confiar en elementos subyacentes:

- Sistemas de caches
- Servicios propios de terceros
- De ser posible tener fallbacks a la mano.

** Controlar los límites de tus capacidades.

- Conoce el limite de tus capacidades
- máximo throughput permitido 
- APlica como medidas alguna técnica para evitar que la contrapresión corrompa tu infraestructura.

** Siempre Observabilidad
- Traceo distribuido
- Log Aggregation 
- Samart health check ( Verificar los elementos de nuestra aplicación on los cual interactua)
- Exceptio  Tracking
- Métricas de Aplicaciones (APM)

** Evitar las mismas funcionalidades en los serrvicios



* BEnefits of autonomous software components
 I learned that descomposing the platform´s functionality into a set of autonomous software components 
 provides a number of benefits:_
 
 * A customer ca deploy parts of the platform in its own system landscape, integrating it with 
 its existing system using its well-defined APIS
 System A and System B
 
 * Another customer could choose to replace parts of the platform´s functionality with implementations 
 that already exist in the customer´s system landscape, potentially requiring some adoption of the existing 
 functionality in the platform APIs.
 
 * Each component in the platform can be delivered and upgraded separately. Thanks to the use of well-defined
 APIs, one component can be upgraded to a new version without being dependent on the life cycle of the other
 components.
 
 * Thanks to the use of well-defined APIs, each component in the platform can also be scaled out to multiple 
 servers independently of the other components. Scaling can be done either to meet high availability 
 requirements or to handle higher volumes of requests. In this specific project, it was achieved by manually
 setting up load balancers in front of a number of servers, each running a Java EE web container
 
 Scalig platform 
 
 ** vChallenges with autonomous software components
 
 }
Figure 1.6: Scaling out the platform

Challenges with autonomous software components
My team also learned that decomposing the platform introduced a number of new challenges that we were not exposed to (at least not to the same degree) when developing more traditional, monolithic applications:

*Adding new instances to a component required manually configuring load balancers and manually setting up new
 nodes. This work was both time-consuming and error-prone.
 
*The platform was initially prone to errors caused by the other systems it was communicating with. 
If a system stopped responding to requests that were sent from the platform in a timely fashion, 
the platform quickly ran out of crucial resources, for example, OS threads, specifically when exposed 
to a large number of concurrent requests. This caused components in the platform to hang or even crash.
 Since most of the communication in the platform is based on synchronous communication, one component
 crashing can lead to cascading failures; that is, clients of the crashing components could also crash 
 after a while. This is known as a chain of failures.
 
*Keeping the configuration in all the instances of the components consistent and up to date quickly 
became a problem, causing a lot of manual and repetitive work. This led to quality problems from time 
to time.

*Monitoring the state of the platform in terms of latency issues and hardware usage (for example, usage
 of CPU, memory, disks, and the network) was more complicated compared to monitoring a single instance
 of a monolithic application.
 
*Collecting log files from a number of distributed components and correlating related log events from
 the components was also difficult, but feasible since the number of components was fixed and known
 in advance.
 
 ** Enter microservices
  Many microservice pioneers had published details of lessons they’d learned. It was very interesting 
  to learn from these lessons.
  
  Some of these are as follows:

* Pivotal released Spring Cloud, which wraps parts of the Netflix OSS in order to provide capabilities
 such as dynamic service discovery, configuration management, distributed tracing, circuit breaking, 
 and more.
 
* I also learned about Docker and the container revolution, which is great for minimizing the gap between 
development and production. Being able to package a component not only as a deployable runtime artifact 
(for example, a Java war or jar file) but as a complete image, ready to be launched as a container on a 
server running Docker, was a great step forward for development and testing.

* In 2018, I started to learn about the concept of a service mesh and how a service mesh can complement a 
}container orchestrator to further offload microservices from responsibilities to make them manageable and
 resilient.
 
**  A sample microsrewvice landscape 
 
 how they can be used together to create cooperating microservices that are manageable, scalable, and resilient.
 
 
 Product composite-. Product mMS, Review MS, Recommendation MS. 
 
 ** Defining a microservice
 
 A micoprsrevices arquitecture is about splitting up monolithic application into smaller components, which
 achieve s two major goals:
 
 * Faster development, enabling continuous deployments
 * Easier to scale, manually or automatically
 
 A microservice is essentially an autonomous software component that is independently upgradeable, 
 replaceable, and scalable.
 
 microservices criterios
 
 must fulfill certain criteria, as follows:
 
* It must conform to a shared-nothing architecture; that is, microservices don’t share data in databases
 with each other!
*It must only communicate through well-defined interfaces, either using APIs and synchronous services or
 preferably by sending messages asynchronously. The APIs and message formats used must be stable, well 
 }documented, and evolve by following a defined versioning strategy.
* It must be deployed as separate runtime processes. Each instance of a microservice runs in a separate 
runtime process, for example, a Docker container.
* Microservice instances are stateless so that incoming requests to a microservice can be handled by any 
of its instances.

How big should a microservice be?}
* Small enough to fit in the head of a developer
* Big enough to not jeopardize performance (that is, latency) and/or data consistency (SQL foreign keys 
between data that’s stored in different microservices are no longer something you can take for granted)}


** Challenges with micorservices

- Many small components that use synchronous communication can cause a chain of failure problem,
 especially under high load
- Keeping the configuration up to date for many small components can be challenging
- It’s hard to track a request that’s being processed and involves many components, for example,
 when performing root cause analysis, where each component stores log records locally
- Analyzing the usage of hardware resources on a component level can be challenging as well
- Manual configuration and management of many small components can become costly and error-prone


 // The 8 fallacies of distributed computing:
1. The network is reliable
2. Latency is zero
3. Bandwidth is infinite
4. The network is secure
5. The topology doesn’t change
6. There is one administrator
7. The transport cost is zero
8. The network is homogeneous

— Peter Deutsch, 1994

*** Design patterns for Microservices

how we can implement these design patterns using Spring Boot, Spring Cloud, Kubernetes, and Istio.

The design patterns we will cover are as follows:

* Service discovery
* Edge server
* Reactive microservices
* Central configuration
* Centralized log analysis
* Distributed tracing
* Circuit breaker
* Control loop
* Centralized monitoring and alarms

The context for these design patterns is a system landscape of cooperating microservices where the
 microservices communicate with each other using either synchronous requests (for example, using HTTP)
 or by sending asynchronous messages (for example, using a message broker)
 
 --// Service discovery
 
 How can clients find microservices and their instances?
Problem 
Microservices instances are typically assigned dynamically allocated IP addresses when they start up,
 for example, when running in containers. This makes it difficult for a client to make a request to a
 microservice that, for example, exposes a REST API over HTTP. Consider the following diagram:
 
 
 ** Solution 
 
 Add a new component – a service discovery service – to the system landscape, which keeps track of
 currently available microservices and the IP addresses of its instances.
 
 Solution requirements
 
- Automatically register/unregister microservices and their instances as they come and go.
- The client must be able to make a request to a logical endpoint for the microservice. The request will
 be routed to one of the available microservice instances.
- Requests to a microservice must be load-balanced over the available instances.
- We must be able to detect instances that currently are unhealthy so that requests will not be routed to them.

his design pattern can be implemented using two different strategies:

- Client-side routing: The client uses a library that communicates with the service discovery service to find 
out the proper instances to send the requests to.
- Server-side routing: The infrastructure of the service discovery service also exposes a reverse proxy that
 all requests are sent to. The reverse proxy forwards the requests to a proper microservice instance on 
 behalf of the client.
 
 --// Edge Server
 
 Problem
 
 In a system landscape of microservices, it is in many cases desirable to expose some of the microservices
 to the outside of the system landscape and hide the remaining microservices from external access. The
 exposed microservices must be protected against requests from malicious clients.
 
 Implementation notes: An edge server typically behaves like a reverse proxy and can be integrated with a 
 discovery service to provide dynamic load-balancing capabilities.
 
 Solution requirements
 
 * Hide internal services that should not be exposed outside their context; that is, only route requests
 to microservices that are configured to allow external requests
* Expose external services and protect them from malicious requests; that is, use standard protocols and 
best practices such as OAuth, OIDC, JWT tokens, and API keys to ensure that the clients are trustworthy

** Reactive Microsrervices

Problem

Traditionally, as Java developers, we are used to implementing synchronous communication using blocking I/O, 
for example, a RESTful JSON API over HTTP. Using a blocking I/O means that a thread is allocated from the 
operating system for the length of the request.

If the number of concurrent requests goes up, a server might run out of available threads in the operating
 system, causing problems ranging from longer response times to crashing servers. Using a microservice 
 architecture typically makes this problem even worse, where typically a chain of cooperating microservices 
 is used to serve a request. The more microservices involved in serving a request, the faster the available 
 threads will be drained.
 
 Solution
Use non-blocking I/O to ensure that no threads are allocated while waiting for processing to occur in
 another service, that is, a database or another microservice.
 
 - Whenever feasible, use an asynchronous programming model, sending messages without waiting for the 
 receiver to process them.
- If a synchronous programming model is preferred, use reactive frameworks that can execute synchronous
 requests using non-blocking I/O, without allocating a thread while waiting for a response. This will make
 the microservices easier to scale in order to handle an increased workload.
- Microservices must also be designed to be resilient and self-healing. Resilient meaning being capable 
of producing a response even if one of the services it depends on fails; self-healing meaning that once the
 failing service is operational again, the microservice must be able to resume using it.
 
 ** Central Configuration
 
 Problem 
 
 An application is, traditionally, deployed together with its configuration, for example, a set 
 of environment variables and/or files containing configuration information. Given a system landscape 
 based on a microservice architecture, that is, with a large number of deployed microservice instances
 , some queries arise:
 
- How do I get a complete picture of the configuration that is in place for all the running microservice 
instances?
- How do I update the configuration and make sure that all the affected microservice instances are updated 
correctly?

Solution
Add a new component, a configuration server, to the system landscape to store the configuration of all
 the microservices, as illustrated by the following diagram:
 
 Solution Requirements
 Make it possible to store configuration information for a group of microservices in one place, with 
 different settings for different environments (for example, dev, test, qa, and prod).
 
 ** Cerntralized log analysis
 
 Centralized log analysis has the following problem, solution, and solution requirements.
 
 Traditionally, an application writes log events to log files that are stored in the local filesystem of the 
 server that the application runs on. Given a system landscape based on a microservice architecture, 
 that is, with a large number of deployed microservice instances on a large number of smaller servers, 
 we can ask the following questions:
 
- How do I get an overview of what is going on in the system landscape when each microservice instance 
writes to its own local log file?
- How do I find out if any of the microservice instances get into trouble and start writing error messages
 to their log files?
- If end users start to report problems, how can I find related log messages; that is, how can I identify
 which microservice instance is the root cause of the problem? The following diagram illustrates the problem:
 
 Solution 
 
 Add a new component that can manage centralized logging and is capable of the following:

- Detecting new microservice instances and collecting log events from them
- Interpreting and storing log events in a structured and searchable way in a central database
- Providing APIs and graphical tools for querying and analyzing log events


Solution requirements
Some solution requirements are as follows:

- Microservices stream log events to standard system output, stdout. This makes it easier for a log collector
 to find the log events compared to when log events are written to microservice-specific log files.
- Microservices tag the log events with the correlation ID described in the next section regarding the 
Distributed tracing design pattern.
- A canonical log format is defined, so that log collectors can transform log events collected from the
 microservices to a canonical log format before log events are stored in the central database.
 Storing log events in a canonical log format is required to be able to query and analyze the collected 
 log events.
 
 ** Distributing tracing 
 
 Problem
It must be possible to track requests and messages that flow between microservices while processing an external 
request to the system landscape.


Add a new component that can manage centralized logging and is capable of the following:

Detecting new microservice instances and collecting log events from them
Interpreting and storing log events in a structured and searchable way in a central database
Providing APIs and graphical tools for querying and analyzing log events
Solution requirements
Some solution requirements are as follows:

- Microservices stream log events to standard system output, stdout. This makes it easier for a log 
collector to find the log events compared to when log events are written to microservice-specific log files.
- Microservices tag the log events with the correlation ID described in the next section regarding the 
Distributed tracing design pattern.
- A canonical log format is defined, so that log collectors can transform log events collected from 
the microservices to a canonical log format before log events are stored in the central database. Storing log events in a canonical log format is required to be able to query and analyze the collected log events.

***Distributed tracing

Distributed tracing has the following problem, solution, and solution requirements.

Problem
It must be possible to track requests and messages that flow between microservices while processing an external request to the system landscape.

Some examples of fault scenarios are as follows:

- If end users start to file support cases regarding a specific failure, how can we identify the microservice 
that caused the problem, that is, the root cause?
- If one support case mentions problems related to a specific entity, for example, a specific order number, 
how can we find log messages related to processing this specific order – for example, log messages from all 
microservices that were involved in processing it?
- If end users start to file support cases regarding an unacceptably long response time, how can we identify 
which microservice in a call chain is causing the delay?

Solution
To track the processing between cooperating microservices, we need to ensure that all related requests and 
messages are marked with a common correlation ID and that the correlation ID is part of all log events.
 Based on a correlation ID, we can use the centralized logging service to find all related log events.
 If one of the log events also includes information about a business-related identifier, for example, 
 the ID of a customer, product, or order, we can find all related log events for that business identifier 
 using the correlation ID.

To be able to analyze delays in a call chain of cooperating microservices, we must be able to collect 
timestamps for when requests, responses, and messages enter and exit each microservice.

Solution requirements

The solution requirements are as follows:

- Assign unique correlation IDs to all incoming or new requests and events in a well-known place, such as a 
header with a standardized name
- When a microservice makes an outgoing request or sends a message, it must add the correlation ID to the
 request and message
- All log events must include the correlation ID in a predefined format so that the centralized logging 
service can extract the correlation ID from the log event and make it searchable
- Trace records must be created for when requests, responses, and messages both enter and exit a microservice 
instance

** Circuit Braker

Problem 

A system landscape of microservices that uses synchronous intercommunication can be exposed to a chain of 
failures. If one microservice stops responding, its clients might get into problems as well and stop 
responding to requests from their clients. The problem can propagate recursively throughout a system 
landscape and take out major parts of it.

This is especially common in cases where synchronous requests are executed using blocking I/O, that is, 
blocking a thread from the underlying operating system while a request is being processed. Combined with 
a large number of concurrent requests and a service that starts to respond unexpectedly slowly, thread pools 
can quickly become drained, causing the caller to hang and/or crash. This failure can spread unpleasantly 
quickly to the caller’s caller, and so on.

Solution
Add a circuit breaker that prevents new outgoing requests from a caller if it detects a problem with the
 service it calls.
 
 Solutio  Requirements
 
- Open the circuit and fail fast (without waiting for a timeout) if problems with the service are detected.
- Probe for failure correction (also known as a half-open circuit); that is, allow a single request to go 
through on a regular basis to see whether the service is operating normally again.
- Close the circuit if the probe detects that the service is operating normally again. This capability is 
very important since it makes the system landscape resilient to these kinds of problems; in other words, 
it self-heals.

Therefore, this circuit breaker is open and utilizes fast-fail logic; that is, it does not call the failing 
service and waits for a timeout to occur. Instead, Microservice E can immediately return a response,
 optionally applying some fallback logic before responding:
 
 Ciscuit braker states:
 - Closed
 - Open 
 - HAlf Open
 
 ** Control Loop
 
 Problem 
 In a system landscape with a large number of microservice instances spread out over a number of servers, 
 it is very difficult to manually detect and correct problems such as crashed or hung microservice instances.
 
 Solution
 
 Add a new component, a control loop, to the system landscape. This process is illustrated as follows:
 
 the control Loop 
 --> Obvserve --> Analyse --> aCT-->
 
 sOLUTION Requirements
 
 The control loop will constantly observe the actual state of the system landscape, comparing it with a 
 desired state, as specified by the operators. If the two states differ, it will take action to make the 
 actual state equal to the desired state.

Implementation notes: In the world of containers, a container orchestrator such as Kubernetes is typically 
used to implement this pattern. We will learn more about Kubernetes in Chapter 15, Introduction to Kubernetes.

** Centralized monitoring and alarms

Problem
If observed response times and/or the usage of hardware resources become unacceptably high, it can be very 
hard to discover the root cause of the problem. For example, we need to be able to analyze hardware resource 
consumption per microservice.

Solution
To curb this, we add a new component, a monitor service, to the system landscape, which is capable of 
collecting metrics about hardware resource usage for each microservice instance level.

Solution requirements

The solution requirements are as follows:

- It must be able to collect metrics from all the servers that are used by the system landscape, which
 includes autoscaling servers
- It must be able to detect new microservice instances as they are launched on the available servers and 
start to collect metrics from them
- It must be able to provide APIs and graphical tools for querying and analyzing the collected metrics
- It must be possible to define alerts that are triggered when a specified metric exceeds a specified 
threshold value

The following screenshot shows Grafana, which visualizes metrics from Prometheus, a monitoring tool that we 
will look at in Chapter 20, Monitoring Microservices:

** Software enablers

we have a number of very good open source tools that can help us both meet our expectations of microservices 
and, most importantly, handle the new challenges that come with them:

- Spring Boot, an application framework
- Spring Cloud/Netflix OSS, a mix of application framework and ready-to-use services
- Docker, a tool for running containers on a single server
- Kubernetes, a container orchestrator that manages a cluster of servers that run containers
- Istio, a service mesh implementation

** Other important considerations

-- Importance of DevOps: 
-- Organizational aspects and Conway’s law: ”Any organization that designs a system (defined broadly) will 
produce a design whose structure is a copy of the organization’s communication structure.”
 Melvyn Conway, 1967
 
 To successfully deliver an application based on a microservice architecture, the organization needs to be 
 changed into teams that work with one or a group of related microservices. The team must have the skills 
 that are required for those microservices, for example, languages and frameworks for the business logic and
 database technologies for persisting its data.
 
-- Decomposing a monolithic application into microservices: 
One of the most difficult decisions
 (and expensive if done wrong) is how to decompose a monolithic application into a set of cooperating 
 microservices. If this is done in the wrong way, you will end up with problems such as the following:

- Slow delivery: Changes in the business requirements will affect too many of the microservices, resulting in extra work.
- Bad performance: To be able to perform a specific business function, a lot of requests have to be passed between various microservices, resulting in long response times.
- Inconsistent data: Since related data is separated into different microservices, inconsistencies can appear over time in data that’s managed by different microservices.
A good approach to finding proper boundaries for microservices is to apply Domain-driven design and its concept of bounded contexts. According to Eric Evans, a bounded 
context is:

Importance of API design: If a group of microservices exposes a common, externally available API, it is 
important that the API is easy to understand and adheres to the following guidelines:

- If the same concept is used in multiple APIs, it should have the same description in terms of the naming 
and data types used.
- It is of great importance that APIs are allowed to evolve in an independent but controlled manner. This
 typically requires applying a proper versioning schema for the APIs, for example,
 https://semver.org/. This implies supporting multiple major versions of an API over a specific period of 
 time, allowing clients of the API to migrate to new major versions at their own pace.
 
- Migration paths from on-premises to the cloud
- Good design principles for microservices, the 12-factor app: The 12-factor app (https://12factor.net